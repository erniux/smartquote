# ai_agent/test_generator.py
# para ejecuci√≥n:
# python ai_agent/test_generator.py --app_name=companies

import os
import re
import json
import time
import httpx
import ollama
import subprocess
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from ai_agent.reader import CodeReader
from ai_agent.config import Config
from ai_agent.frontend_reader import FrontendReader


class TestGenerator:
    """Agente para generar pruebas automatizadas basadas en c√≥digo fuente y modelos Ollama."""

    def __init__(self, fast_mode=False, app_name=None, export=False, fallback=False, source="backend"):
        self.config = Config()
        self.source = source
        # Elegir reader seg√∫n la fuente
        if source == "frontend":
            self.reader = FrontendReader(app_name=app_name)
        else:
            self.reader = CodeReader(app_name=app_name)

        print(f"üìö Source seleccionado: {self.source} | Reader: {self.reader.__class__.__name__}")

        self.fast_mode = fast_mode
        self.app_name = app_name
        self.export = export
        self.fallback = fallback
        self.start_time = datetime.now()

        # üëá ahora los .feature van directo a la misma carpeta de features de BDD
        self.features_dir = "/app/bdd/tests/features"
        self.logs_dir = "/app/outputs/logs"

        print(f"üöÄ Inicializando TestGenerator con modelo={self.config.OLLAMA_MODEL}")
        print(f"üß© Conectando cliente Ollama en {self.config.OLLAMA_BASE_URL} ...")

        # Cliente Ollama
        self.client = ollama.Client(host=self.config.OLLAMA_BASE_URL.strip())

        # Verificar disponibilidad
        self.wait_for_ollama(self.config.OLLAMA_BASE_URL)
        print(f"‚úÖ Cliente Ollama inicializado correctamente en {self.config.OLLAMA_BASE_URL}")

    # ----------------------------
    # üîç Verificaci√≥n de disponibilidad
    # ----------------------------
    def wait_for_ollama(self, url, timeout=300):
        """Verifica que Ollama est√© corriendo y que el modelo requerido est√© disponible."""
        model_name = self.config.OLLAMA_MODEL
        print(f"üïì Esperando a Ollama y al modelo '{model_name}' ...")

        start = time.time()
        while time.time() - start < timeout:
            try:
                response = httpx.get(f"{url}/api/tags", timeout=10)
                if response.status_code == 200:
                    tags = response.json().get("models", [])
                    model_names = [t.get("name", "") for t in tags]
                    if any(model_name in name for name in model_names):
                        print(f"‚úÖ Ollama y el modelo '{model_name}' est√°n listos.")
                        return True
                    else:
                        print(f"üîÅ Modelo '{model_name}' a√∫n no descargado, esperando...")
                else:
                    print(f"‚ö†Ô∏è Ollama responde con c√≥digo {response.status_code}, reintentando...")
            except Exception as e:
                print(f"‚è≥ A√∫n no responde ({str(e)}), reintentando...")

            time.sleep(5)

        raise ConnectionError(
            f"‚ùå Tiempo agotado esperando a que Ollama y el modelo '{model_name}' est√©n listos."
        )

    # ----------------------------
    # ‚öôÔ∏è  Generador principal de pruebas
    # ----------------------------
    def generate_tests(self):
        """Genera los tests features autom√°ticamente a partir del c√≥digo fuente."""
        os.makedirs(self.features_dir, exist_ok=True)
        os.makedirs(self.logs_dir, exist_ok=True)

        files = self.reader.read_files()
        total_files = len(files)
        print(f"üìÇ Se leer√°n {total_files} archivos para an√°lisis...")

        # Agrupar archivos por carpeta (app)
        grouped_files = defaultdict(list)
        for path, content in files.items():
            folder = os.path.basename(os.path.dirname(path))  # quotations, sales, etc.
            grouped_files[folder].append((path, content))

        print(f"üì¶ Se agrupar√°n {len(grouped_files)} m√≥dulos para an√°lisis...")

        for i, (folder, file_list) in enumerate(grouped_files.items(), start=1):
            print(f"üß© Procesando m√≥dulo {i}/{len(grouped_files)}: {folder}")

            # Unir contenido
            combined_content = "\n\n".join(
                [f"# Archivo: {os.path.basename(p)}\n{c}" for p, c in file_list]
            )

            # Prompts estrictos por fuente
            if self.source == "backend":
                system_prompt = (
                    "You are a Senior QA Automation Engineer (SDET). "
                    "You output ONLY strict and valid Gherkin: no markdown, no comments, no prose."
                )
                prompt = f"""
Analyze Django module **{folder}** (models/serializers/views) and generate a SINGLE valid Gherkin .feature
for API behaviors (auth, CRUD, validation, permissions, HTTP errors).
STRICT RULES:
- Return ONLY Gherkin content.
- Start with 'Feature: {folder.title()} API'
- Include multiple 'Scenario:' blocks with Given/When/Then (and And/But).
- Include edge cases as possible.
- No natural-language paragraphs, no explanations, no code fences.

{combined_content}
"""
            else:
                system_prompt = (
                    "You are a Senior QA Engineer specialized in Web E2E with Playwright. "
                    "You output ONLY strict and valid Gherkin: no markdown, no comments, no prose."
                )
                prompt = f"""
Analyze React module **{folder}** (pages/components) and generate a SINGLE valid Gherkin .feature
for UI flows (navigation, login, forms, clicks, success/error messages, route guards).
STRICT RULES:
- Return ONLY Gherkin content.
- Start with 'Feature: {folder.title()} UI'
- Include multiple 'Scenario:' blocks with Given/When/Then (and And/But).
- Include edge cases as possible.
- No natural-language paragraphs, no explanations, no code fences.

{combined_content}
"""

            # Llamada al modelo (1¬™)
            response = self.client.chat(
                model=self.config.OLLAMA_MODEL,
                messages=[{"role": "system", "content": system_prompt},
                          {"role": "user", "content": prompt}],
            )
            answer = response["message"]["content"]

            # 2¬™ vuelta pidiendo SOLO Gherkin (refuerzo)
            response = self.client.chat(
                model=self.config.OLLAMA_MODEL,
                messages=[{"role": "user", "content": f"Return ONLY valid Gherkin for the previous analysis.\n{answer}"}],
            )
            answer = response["message"]["content"]

            # Validar + sanitizar Gherkin
            if not self._is_valid_gherkin(answer):
                print("‚ö†Ô∏è Respuesta no v√°lida como Gherkin. Reintentando con prompt estricto‚Ä¶")
                strict_msgs = self._second_chance_prompt(folder, self.source, combined_content)
                response = self.client.chat(model=self.config.OLLAMA_MODEL, messages=strict_msgs)
                answer = response["message"]["content"]

            answer = self._sanitize_to_gherkin(
                answer,
                title_fallback=f"{folder.title()} {'API' if self.source=='backend' else 'UI'}"
            )

            # ‚úÖ Guardar .feature en la misma carpeta /features/
            suffix = "api" if self.source == "backend" else "ui"
            feature_filename = f"{folder}_{suffix}.feature"
            feature_output_path = os.path.join(self.features_dir, feature_filename)
            with open(feature_output_path, "w", encoding="utf-8") as f:
                f.write(answer)

            print(f"‚úÖ Archivo .feature generado: {feature_output_path}")

        # Log final
        self.save_log(self.features_dir)

    # ----------------------------
    # üíæ Logs
    # ----------------------------
    def save_log(self, _unused_output_path, mode="features"):
        """
        Guarda un log con resumen de ejecuci√≥n y actualiza README.md autom√°ticamente.
        """
        end_time = datetime.now()
        duration = end_time - self.start_time
        log_name = f"ai_agent_report_{end_time.strftime('%Y%m%d_%H%M%S')}.txt"
        os.makedirs(self.logs_dir, exist_ok=True)
        log_path = os.path.join(self.logs_dir, log_name)

        features_base = "/app/bdd/tests/features"
        steps_base = "/app/bdd/tests/steps"  # üëà corregido

        def list_files_safe(path):
            try:
                result = []
                for root, _, files in os.walk(path):
                    for f in files:
                        if f.endswith((".feature", ".py")):
                            result.append(os.path.join(root, f))
                return result
            except FileNotFoundError:
                return []

        features = list_files_safe(features_base)
        steps = list_files_safe(steps_base)

        # ü™∂ Escribir log
        with open(log_path, "w", encoding="utf-8") as log:
            log.write("üß† AI AGENT EXECUTION REPORT\n")
            log.write("=" * 60 + "\n")
            log.write(f"üìÖ Inicio: {self.start_time}\n")
            log.write(f"üìÖ Fin: {end_time}\n")
            log.write(f"üß© App: {self.app_name or 'Todas las apps'}\n")
            log.write(f"ü§ñ Modelo: {self.config.OLLAMA_MODEL}\n")
            log.write(f"‚öôÔ∏è Modo de ejecuci√≥n: {mode}\n")
            log.write(f"‚è±Ô∏è Duraci√≥n total: {duration}\n")
            log.write("=" * 60 + "\n")

            if features:
                log.write("\nüìÑ Features generados:\n")
                for f in features:
                    log.write(f"   - {f}\n")
            else:
                log.write("\nüìÑ Features: No se encontraron archivos.\n")

            if steps:
                log.write("\nüêç Steps presentes:\n")
                for s in steps:
                    log.write(f"   - {s}\n")
            else:
                log.write("\nüêç Steps: No se encontraron archivos.\n")

            log.write("\n" + "=" * 60 + "\n")
            log.write(f"üóÇ Logs almacenados en: {self.logs_dir}\n")

        print(f"ü™∂ Log detallado guardado en {log_path}")

        # ‚úÖ Actualizar README con resumen
        self.update_readme_e2e(end_time, duration, features, steps, mode)

    def update_readme_e2e(self, end_time, duration, features, steps, mode):
        """Actualiza el README.md con resumen de la √∫ltima ejecuci√≥n."""
        readme_path = os.path.join(
            os.getenv("PROJECT_BASE_PATH", "/workspace"), "ai_agent", "README.md"
        )

        info = f"""
### üß© √öltima ejecuci√≥n
- üìÖ Fecha: `{end_time.strftime("%Y-%m-%d %H:%M:%S")}`
- ü§ñ Modelo usado: `{self.config.OLLAMA_MODEL}`
- üß© App procesada: `{self.app_name or 'Todas las apps'}`
- ‚öôÔ∏è Modo de ejecuci√≥n: `{mode}`
- ‚è±Ô∏è Duraci√≥n: `{duration}`

#### üìÑ Features en `bdd/tests/features`
{chr(10).join(f"- {os.path.relpath(f, '/app')}" for f in features) if features else "No se encontraron features."}

#### üêç Steps en `bdd/tests/steps`
{chr(10).join(f"- {os.path.relpath(s, '/app')}" for s in steps) if steps else "No se encontraron steps."}
"""

        os.makedirs(os.path.dirname(readme_path), exist_ok=True)
        if os.path.exists(readme_path):
            with open(readme_path, "r+", encoding="utf-8") as f:
                content = f.read()
                if "### üß© √öltima ejecuci√≥n" in content:
                    start = content.find("### üß© √öltima ejecuci√≥n")
                    content = content[:start] + info
                else:
                    content += "\n" + info
                f.seek(0)
                f.write(content)
                f.truncate()
        else:
            with open(readme_path, "w", encoding="utf-8") as f:
                f.write("# ü§ñ AI Agent Execution Log\n" + info)

        print("üìò README.md actualizado con resumen ‚úÖ")

    # ----------------------------
    # üß∞ Utilidades de Gherkin
    # ----------------------------
    def _is_valid_gherkin(self, text: str) -> bool:
        if not text:
            return False
        t = text.strip()
        if "Feature:" not in t or "Scenario" not in t:
            return False
        # Debe tener al menos un Given/When/Then (o And/But despu√©s)
        has_step = any(k in t for k in [" Given ", "\nGiven ", " When ", "\nWhen ", " Then ", "\nThen "])
        return has_step

    def _sanitize_to_gherkin(self, text: str, title_fallback: str = "Feature") -> str:
        """
        Conserva SOLO l√≠neas Gherkin: Feature/Background/Scenario/Scenario Outline/Examples y pasos Given/When/Then/And/But.
        Borra cualquier explicaci√≥n, markdown, etc.
        """
        allowed = ("Feature:", "Background:", "Scenario:", "Scenario Outline:", "Examples:",
                   "Given ", "When ", "Then ", "And ", "But ")
        lines = []
        for raw in text.replace("\r\n", "\n").split("\n"):
            line = raw.strip()
            if not line:
                lines.append("")
                continue
            if any(line.startswith(tok) for tok in allowed):
                lines.append(line)
            elif line.startswith("|") and line.endswith("|"):
                lines.append(line)
        cleaned = "\n".join([l for l in lines if l is not None]).strip()
        if not cleaned.startswith("Feature:"):
            cleaned = f"Feature: {title_fallback}\n\n" + cleaned
        return cleaned.strip()

    def _second_chance_prompt(self, folder: str, source: str, combined_content: str) -> list:
        """Mensajes de re-intento hiper-estrictos cuando el modelo narr√≥ en vez de Gherkin."""
        sys = ("You output ONLY strict, valid Gherkin. No explanations, no markdown, no comments. "
               "If information is missing, invent reasonable steps, but still return ONLY Gherkin.")
        if source == "backend":
            usr = f"""Generate a single valid Gherkin .feature for API behaviors of module "{folder}".
Focus on realistic flows and edge cases (auth, 4xx/5xx, permissions, validation).
STRICT RULES:
- Return ONLY Gherkin content.
- Start with 'Feature: {folder.title()} API'
- Include multiple 'Scenario:' blocks with Given/When/Then (and And/But).
- No natural-language paragraphs, no code fences.

{combined_content}
"""
        else:
            usr = f"""Generate a single valid Gherkin .feature for UI behaviors of module "{folder}".
Focus on real user flows (navigation, forms, clicks, messages, guards).
STRICT RULES:
- Return ONLY Gherkin content.
- Start with 'Feature: {folder.title()} UI'
- Include multiple 'Scenario:' blocks with Given/When/Then (and And/But).
- No natural-language paragraphs, no code fences.

{combined_content}
"""
        return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]
