import os
import json
import time
import httpx
import ollama
from datetime import datetime
from ai_agent.reader import CodeReader
from ai_agent.config import Config


class ApiTestGenerator:
    """Agente para generar pruebas automatizadas basadas en c√≥digo fuente y modelos Ollama."""

    def __init__(self, fast_mode=False, app_name=None, export=False, fallback=False):
        self.config = Config()
        self.reader = CodeReader(app_name=app_name)
        self.fast_mode = fast_mode
        self.app_name = app_name
        self.export = export
        self.fallback = fallback
        self.start_time = datetime.now()
        self.output_dir = "/app/outputs/tests"
        self.logs_dir = "/app/outputs/logs"

        print(f"üöÄ Inicializando ApiTestGenerator con modelo={self.config.OLLAMA_MODEL}")
        print(f"üß© Conectando cliente Ollama en {self.config.OLLAMA_BASE_URL} ...")

        # Crear cliente oficial de Ollama
        self.client = ollama.Client(host=self.config.OLLAMA_BASE_URL.strip())

        # Verificar que Ollama est√© disponible
        self.wait_for_ollama(self.config.OLLAMA_BASE_URL)
        print(f"‚úÖ Cliente Ollama inicializado correctamente en {self.config.OLLAMA_BASE_URL}")

    # ----------------------------
    # üîç Verificaci√≥n de disponibilidad
    # ----------------------------
    def wait_for_ollama(self, url, timeout=60):
        """Verifica que Ollama est√© corriendo antes de iniciar."""
        print(f"üïì Verificando conexi√≥n con Ollama en {url} ...")
        start = time.time()
        while time.time() - start < timeout:
            try:
                response = httpx.get(f"{url}/api/tags", timeout=5)
                if response.status_code == 200:
                    print("‚úÖ Ollama est√° disponible y responde correctamente.")
                    return True
            except Exception:
                time.sleep(3)
        raise ConnectionError("‚ùå Ollama no respondi√≥ en el tiempo esperado.")

    # ----------------------------
    # ‚öôÔ∏è  Generador principal de pruebas
    # ----------------------------
    def generate_tests(self):
        """Genera los tests autom√°ticamente a partir del c√≥digo fuente."""
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.logs_dir, exist_ok=True)

        files = self.reader.read_files()
        total_files = len(files)
        print(f"üìÇ Se leer√°n {total_files} archivos para an√°lisis...")

        output_path = os.path.join(self.output_dir, "generated_test.py")
        all_tests = []

        for i, (path, content) in enumerate(files.items(), start=1):
            print(f"üß© Procesando bloque {i}/{total_files} ({len(content)} chars)")
            try:
                prompt = f"""
Analiza el siguiente archivo de c√≥digo fuente y genera:

1. Pruebas unitarias o de integraci√≥n usando pytest, con formato profesional.
2. Solo usa comentarios con `#` dentro del c√≥digo (nunca ``` ni ```python).
3. No agregues explicaciones externas ni texto descriptivo fuera del c√≥digo.
4. Al final del archivo, incluye un bloque en formato Gherkin (Feature / Scenario)
   que describa los mismos casos de prueba de forma resumida.

El c√≥digo debe ser funcional y limpio, sin imports innecesarios.

Archivo analizado: {os.path.basename(path)}

{content}
"""

                print(f"üîÑ Enviando prompt a Ollama ({self.config.OLLAMA_BASE_URL})...")
                print(f"üîÑ Enviando prompt ({len(prompt)} chars)...")
                try:
                    start_block = time.time()
                    response = self.client.chat(
                        model=self.config.OLLAMA_MODEL,
                        messages=[{"role": "user", "content": prompt}],
                    )
                    elapsed = round(time.time() - start_block, 2)
                    content = response["message"]["content"]
                    print(f"‚úÖ Respuesta recibida en {elapsed}s: {content[:150]}...")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error procesando bloque {i}: {e}")


                answer = response["message"]["content"]
                print(f"üí¨ Respuesta de Ollama: {answer[:120]}...")

                all_tests.append(f"# ==== Tests para {os.path.basename(path)} ====\n{answer}\n")
                print(f"‚úÖ Bloque {i} procesado correctamente.")
            except Exception as e:
                print(f"‚ö†Ô∏è Error procesando bloque {i}: {e}")

        with open(output_path, "w", encoding="utf-8") as f:
            f.write("\n".join(all_tests))

        print(f"‚úÖ Tests generados en: {output_path}")
        self.save_log(output_path)

        if self.export:
            self.export_results(output_path)

    # ----------------------------
    # üíæ Exportaci√≥n y logs
    # ----------------------------
    def export_results(self, output_path):
        """Copia el archivo generado a la carpeta compartida."""
        export_dir = os.path.join(
            os.getenv("PROJECT_BASE_PATH", "/workspace"), "ai_agent", "outputs", "tests"
        )
        os.makedirs(export_dir, exist_ok=True)

        dest_path = os.path.join(export_dir, "generated_test.py")
        if os.path.abspath(output_path) != os.path.abspath(dest_path):
            os.system(f"cp {output_path} {dest_path}")
            print(f"üì¶ Archivo exportado a {dest_path}")
        else:
            print("‚öôÔ∏è  Archivo ya est√° en la ruta destino, no se copia.")

    def save_log(self, output_path):
        """Guarda log con resumen y actualiza README.md autom√°ticamente."""
        end_time = datetime.now()
        duration = end_time - self.start_time
        log_name = f"ai_agent_report_{end_time.strftime('%Y%m%d_%H%M%S')}.txt"
        log_path = os.path.join(self.logs_dir, log_name)

        with open(log_path, "w", encoding="utf-8") as log:
            log.write("üß† AI AGENT EXECUTION REPORT\n")
            log.write("=" * 40 + "\n")
            log.write(f"üìÖ Inicio: {self.start_time}\n")
            log.write(f"üìÖ Fin: {end_time}\n")
            log.write(f"üß© App: {self.app_name or 'Todas las apps'}\n")
            log.write(f"ü§ñ Modelo: {self.config.OLLAMA_MODEL}\n")
            log.write(
                f"‚öôÔ∏è Par√°metros: {'--fast ' if self.fast_mode else ''}{'--export ' if self.export else ''}{'--fallback' if self.fallback else ''}\n"
            )
            log.write(f"üìÇ Archivos analizados: {len(self.reader.read_files())}\n")
            log.write(f"üìÑ Tests generados: {output_path}\n")
            log.write(f"‚è±Ô∏è Duraci√≥n total: {duration}\n")
            log.write("=" * 40 + "\n")

        print(f"ü™∂ Log guardado en {log_path}")
        self.update_readme(end_time, duration)

    def update_readme(self, end_time, duration):
        """Actualiza el README.md con la informaci√≥n de la √∫ltima ejecuci√≥n."""
        readme_path = os.path.join(
            os.getenv("PROJECT_BASE_PATH", "/workspace"), "ai_agent", "README.md"
        )
        info = f"""
### üßæ √öltima ejecuci√≥n registrada
- üìÖ Fecha: `{end_time.strftime("%Y-%m-%d %H:%M:%S")}`
- ü§ñ Modelo usado: `{self.config.OLLAMA_MODEL}`
- üß© App procesada: `{self.app_name or 'Todas las apps'}`
- ‚öôÔ∏è Par√°metros: {'--fast' if self.fast_mode else ''} {'--export' if self.export else ''} {'--fallback' if self.fallback else ''}
- ‚è±Ô∏è Duraci√≥n: `{duration}`
"""
        os.makedirs(os.path.dirname(readme_path), exist_ok=True)
        if os.path.exists(readme_path):
            with open(readme_path, "r+", encoding="utf-8") as f:
                content = f.read()
                if "### üßæ √öltima ejecuci√≥n registrada" in content:
                    start = content.find("### üßæ √öltima ejecuci√≥n registrada")
                    content = content[:start] + info
                else:
                    content += "\n" + info
                f.seek(0)
                f.write(content)
                f.truncate()
            print("ü™∂ README.md actualizado autom√°ticamente con la √∫ltima ejecuci√≥n.")
        else:
            with open(readme_path, "w", encoding="utf-8") as f:
                f.write("# ü§ñ AI Agent Execution Log\n" + info)
            print(f"üìò README.md creado autom√°ticamente en {readme_path}")


    def _convert_to_feature(self, name, body):
        """
        Convierte c√≥digo de test en formato Gherkin b√°sico.
        Si el cuerpo ya contiene un bloque 'Feature:', lo conserva tal cual.
        """
        # Si ya tiene un bloque Gherkin generado por Ollama, lo reutilizamos
        if "Feature:" in body:
            feature_match = re.search(r"(Feature:.*)", body, re.DOTALL)
            if feature_match:
                return feature_match.group(1)

        # Caso contrario: generar autom√°ticamente los escenarios desde las funciones test_
        scenarios = re.findall(r"def test_(\w+)", body)
        feature = [f"Feature: {name.replace('_', ' ').title()}"]

        for scenario in scenarios:
            feature.append(f"\n  Scenario: {scenario.replace('_', ' ').title()}")
            feature.append(f"    Given el sistema est√° listo")
            feature.append(f"    When se ejecuta el test {scenario}")
            feature.append(f"    Then el resultado es exitoso")

        return "\n".join(feature)

